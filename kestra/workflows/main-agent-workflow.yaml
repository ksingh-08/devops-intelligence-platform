id: devops-intelligence-main
namespace: devops.intelligence

description: |
  Main DevOps Intelligence Platform workflow that orchestrates the entire 
  autonomous incident response system. Monitors production systems, 
  generates AI summaries, triggers code fixes, and manages deployments.

inputs:
  - id: monitoring_interval
    type: DURATION
    defaults: PT5M
    description: How often to check for issues (default: 5 minutes)
  
  - id: confidence_threshold
    type: FLOAT
    defaults: 0.8
    description: Minimum confidence score for autonomous actions
  
  - id: max_auto_deployments
    type: INT
    defaults: 5
    description: Maximum autonomous deployments per hour

variables:
  datadog_base_url: "https://api.datadoghq.com/api/v1"
  newrelic_base_url: "https://api.newrelic.com/v2"
  github_base_url: "https://api.github.com"
  sentry_base_url: "https://sentry.io/api/0"

triggers:
  - id: scheduled_monitoring
    type: io.kestra.core.models.triggers.types.Schedule
    cron: "*/5 * * * *"  # Every 5 minutes
    description: Continuous monitoring trigger

  - id: webhook_trigger
    type: io.kestra.core.models.triggers.types.Webhook
    key: "incident-alert"
    description: Manual incident trigger via webhook

tasks:
  # =============================================================================
  # PHASE 1: DATA COLLECTION FROM MULTIPLE SOURCES
  # =============================================================================
  
  - id: collect_datadog_logs
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.datadog_base_url }}/logs-queries/list"
    method: GET
    headers:
      DD-API-KEY: "{{ secret('DATADOG_API_KEY') }}"
      DD-APPLICATION-KEY: "{{ secret('DATADOG_APP_KEY') }}"
    body: |
      {
        "query": "status:error OR status:critical",
        "time": {
          "from": "now-5m",
          "to": "now"
        },
        "sort": "timestamp",
        "limit": 100
      }
    description: Collect error logs from Datadog

  - id: collect_newrelic_metrics
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.newrelic_base_url }}/applications.json"
    method: GET
    headers:
      X-Api-Key: "{{ secret('NEW_RELIC_API_KEY') }}"
    description: Collect application metrics from New Relic

  - id: collect_github_issues
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.github_base_url }}/repos/{{ secret('GITHUB_OWNER') }}/{{ secret('GITHUB_REPO') }}/issues"
    method: GET
    headers:
      Authorization: "token {{ secret('GITHUB_TOKEN') }}"
    body: |
      {
        "state": "open",
        "labels": "bug,critical,production",
        "since": "{{ now() | dateAdd(-5, 'MINUTES') | date('yyyy-MM-dd\'T\'HH:mm:ss\'Z\'') }}"
      }
    description: Collect recent critical issues from GitHub

  - id: collect_sentry_errors
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.sentry_base_url }}/projects/{{ secret('SENTRY_ORG') }}/{{ secret('SENTRY_PROJECT') }}/events/"
    method: GET
    headers:
      Authorization: "Bearer {{ secret('SENTRY_AUTH_TOKEN') }}"
    body: |
      {
        "query": "is:unresolved",
        "statsPeriod": "5m"
      }
    description: Collect unresolved errors from Sentry

  - id: collect_cloudwatch_logs
    type: io.kestra.plugin.aws.logs.CloudWatchLogsQuery
    accessKeyId: "{{ secret('AWS_ACCESS_KEY_ID') }}"
    secretKeyId: "{{ secret('AWS_SECRET_ACCESS_KEY') }}"
    region: "{{ secret('AWS_REGION') }}"
    logGroupName: "{{ secret('AWS_LOG_GROUP_NAME') }}"
    startTime: "{{ now() | dateAdd(-5, 'MINUTES') }}"
    endTime: "{{ now() }}"
    queryString: "ERROR OR CRITICAL OR FATAL"
    description: Collect error logs from AWS CloudWatch

  # =============================================================================
  # PHASE 2: DATA PROCESSING AND AGGREGATION
  # =============================================================================

  - id: process_collected_data
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    beforeCommands:
      - pip install pandas requests python-dateutil
    script: |
      import json
      import pandas as pd
      from datetime import datetime, timedelta
      
      # Load collected data from previous tasks
      datadog_data = {{ outputs.collect_datadog_logs.body }}
      newrelic_data = {{ outputs.collect_newrelic_metrics.body }}
      github_data = {{ outputs.collect_github_issues.body }}
      sentry_data = {{ outputs.collect_sentry_errors.body }}
      cloudwatch_data = {{ outputs.collect_cloudwatch_logs.results }}
      
      # Process and normalize data
      processed_data = {
          "timestamp": datetime.now().isoformat(),
          "sources": {
              "datadog": {
                  "error_count": len(datadog_data.get("logs", [])),
                  "critical_errors": [log for log in datadog_data.get("logs", []) if log.get("status") == "critical"],
                  "summary": f"Found {len(datadog_data.get('logs', []))} errors in last 5 minutes"
              },
              "newrelic": {
                  "app_count": len(newrelic_data.get("applications", [])),
                  "error_rate": sum([app.get("error_rate", 0) for app in newrelic_data.get("applications", [])]),
                  "summary": f"Average error rate across {len(newrelic_data.get('applications', []))} applications"
              },
              "github": {
                  "open_issues": len(github_data),
                  "critical_issues": [issue for issue in github_data if "critical" in [label["name"] for label in issue.get("labels", [])]],
                  "summary": f"{len(github_data)} open issues, {len([i for i in github_data if 'critical' in [l['name'] for l in i.get('labels', [])]])} critical"
              },
              "sentry": {
                  "error_count": len(sentry_data),
                  "unresolved_errors": sentry_data,
                  "summary": f"{len(sentry_data)} unresolved errors detected"
              },
              "cloudwatch": {
                  "log_events": len(cloudwatch_data),
                  "error_logs": cloudwatch_data,
                  "summary": f"{len(cloudwatch_data)} error events in CloudWatch logs"
              }
          },
          "overall_health": "degraded" if any([
              len(datadog_data.get("logs", [])) > 10,
              sum([app.get("error_rate", 0) for app in newrelic_data.get("applications", [])]) > 5.0,
              len([i for i in github_data if "critical" in [l["name"] for l in i.get("labels", [])]]) > 0,
              len(sentry_data) > 5,
              len(cloudwatch_data) > 20
          ]) else "healthy"
      }
      
      print(json.dumps(processed_data, indent=2))
    description: Process and aggregate data from all monitoring sources

  # =============================================================================
  # PHASE 3: AI-POWERED ANALYSIS AND SUMMARIZATION
  # =============================================================================

  - id: ai_analysis_and_summary
    type: io.kestra.plugin.ai.Agent
    model: gpt-4-turbo-preview
    apiKey: "{{ secret('OPENAI_API_KEY') }}"
    systemPrompt: |
      You are an expert DevOps AI agent responsible for analyzing production issues 
      and making autonomous decisions. Analyze the provided monitoring data and:
      
      1. Identify the most critical issues requiring immediate attention
      2. Determine root causes based on patterns across data sources
      3. Assess the severity and impact of each issue
      4. Recommend specific actions (fix code, scale resources, rollback, etc.)
      5. Provide confidence scores for your recommendations
      6. Decide if issues can be auto-resolved or need human escalation
      
      Respond in JSON format with structured analysis and clear action items.
    
    userPrompt: |
      Analyze this production monitoring data and provide autonomous decision recommendations:
      
      {{ outputs.process_collected_data.vars.stdout }}
      
      Consider:
      - Error patterns and frequency
      - Cross-system correlations  
      - Historical incident data
      - Business impact assessment
      - Auto-resolution feasibility
      
      Provide specific, actionable recommendations with confidence scores.
    
    tools:
      - type: web_search
        description: Search for similar issues and solutions
      - type: code_analysis
        description: Analyze code repositories for potential fixes
    
    memory:
      enabled: true
      type: conversation
      maxTokens: 8000
    
    description: AI Agent analyzes monitoring data and provides autonomous recommendations

  # =============================================================================
  # PHASE 4: DECISION ENGINE AND ACTION PLANNING
  # =============================================================================

  - id: decision_engine
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    beforeCommands:
      - pip install json5
    script: |
      import json
      import json5
      from datetime import datetime
      
      # Parse AI analysis results
      ai_analysis = json5.loads('''{{ outputs.ai_analysis_and_summary.response }}''')
      
      # Decision engine logic
      decisions = []
      auto_actions = []
      escalations = []
      
      confidence_threshold = {{ inputs.confidence_threshold }}
      
      for recommendation in ai_analysis.get("recommendations", []):
          confidence = recommendation.get("confidence_score", 0.0)
          action_type = recommendation.get("action_type", "unknown")
          severity = recommendation.get("severity", "medium")
          
          decision = {
              "id": f"decision_{len(decisions) + 1}",
              "timestamp": datetime.now().isoformat(),
              "recommendation": recommendation,
              "confidence": confidence,
              "action_type": action_type,
              "severity": severity,
              "decision": "auto" if confidence >= confidence_threshold and severity != "critical" else "escalate",
              "reasoning": f"Confidence {confidence:.2f} {'meets' if confidence >= confidence_threshold else 'below'} threshold {confidence_threshold}"
          }
          
          decisions.append(decision)
          
          if decision["decision"] == "auto":
              auto_actions.append(decision)
          else:
              escalations.append(decision)
      
      result = {
          "timestamp": datetime.now().isoformat(),
          "total_decisions": len(decisions),
          "auto_actions": len(auto_actions),
          "escalations": len(escalations),
          "decisions": decisions,
          "next_actions": auto_actions[:3],  # Limit to 3 concurrent actions
          "escalation_required": len(escalations) > 0
      }
      
      print(json.dumps(result, indent=2))
    description: Decision engine processes AI recommendations and determines autonomous actions

  # =============================================================================
  # PHASE 5: AUTONOMOUS CODE GENERATION (CLINE CLI)
  # =============================================================================

  - id: trigger_cline_code_generation
    type: io.kestra.plugin.core.flow.ForEach
    values: "{{ outputs.decision_engine.vars.stdout | jq('.next_actions[]') }}"
    tasks:
      - id: generate_fix_code
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - echo "Generating fix for issue: {{ taskrun.value.recommendation.issue_description }}"
          - |
            cd /tmp/cline-workspace
            
            # Prepare context for Cline CLI
            cat > issue_context.json << EOF
            {
              "issue": {{ taskrun.value.recommendation | tojson }},
              "confidence": {{ taskrun.value.confidence }},
              "severity": "{{ taskrun.value.severity }}",
              "suggested_fix": "{{ taskrun.value.recommendation.suggested_fix }}"
            }
            EOF
            
            # Call Cline CLI to generate fix code
            cline --config /app/cline/config.json \
                  --prompt "Generate fix code for this production issue" \
                  --context issue_context.json \
                  --output fix_output.json \
                  --auto-approve
            
            # Extract generated code
            cat fix_output.json
        description: Use Cline CLI to generate fix code for identified issues

  # =============================================================================
  # PHASE 6: CODE REVIEW AND VALIDATION
  # =============================================================================

  - id: create_pull_request
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.github_base_url }}/repos/{{ secret('GITHUB_OWNER') }}/{{ secret('GITHUB_REPO') }}/pulls"
    method: POST
    headers:
      Authorization: "token {{ secret('GITHUB_TOKEN') }}"
      Content-Type: "application/json"
    body: |
      {
        "title": "ðŸ¤– Autonomous Fix: {{ outputs.ai_analysis_and_summary.response | jq('.recommendations[0].issue_description') }}",
        "body": "## Autonomous Fix Generated by DevOps Intelligence Platform\n\n**Issue Analysis:**\n{{ outputs.ai_analysis_and_summary.response | jq('.recommendations[0]') | tojson }}\n\n**Generated Fix:**\n```\n{{ outputs.trigger_cline_code_generation.outputs.generate_fix_code.vars.stdout }}\n```\n\n**Confidence Score:** {{ outputs.decision_engine.vars.stdout | jq('.next_actions[0].confidence') }}\n\n**Auto-generated by:** Kestra AI Agent + Cline CLI\n**Timestamp:** {{ now() }}",
        "head": "autonomous-fix-{{ now() | date('yyyyMMdd-HHmmss') }}",
        "base": "main"
      }
    description: Create pull request with generated fix code

  # =============================================================================
  # PHASE 7: DEPLOYMENT DECISION AND EXECUTION
  # =============================================================================

  - id: deployment_decision
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    script: |
      import json
      from datetime import datetime
      
      # Check if CodeRabbit approved the PR (simulated for demo)
      coderabbit_approved = True  # In real implementation, check via webhook
      
      # Get decision data
      decisions = json.loads('''{{ outputs.decision_engine.vars.stdout }}''')
      
      # Deployment logic
      should_deploy = (
          decisions.get("auto_actions", 0) > 0 and
          coderabbit_approved and
          decisions.get("escalation_required", False) == False
      )
      
      deployment_decision = {
          "timestamp": datetime.now().isoformat(),
          "should_deploy": should_deploy,
          "coderabbit_approved": coderabbit_approved,
          "auto_actions_count": decisions.get("auto_actions", 0),
          "reasoning": "All conditions met for autonomous deployment" if should_deploy else "Manual review required"
      }
      
      print(json.dumps(deployment_decision, indent=2))
    description: Make final deployment decision based on all factors

  - id: deploy_to_vercel
    type: io.kestra.plugin.core.http.Request
    condition: "{{ outputs.deployment_decision.vars.stdout | jq('.should_deploy') }}"
    uri: "https://api.vercel.com/v1/deployments"
    method: POST
    headers:
      Authorization: "Bearer {{ secret('VERCEL_TOKEN') }}"
      Content-Type: "application/json"
    body: |
      {
        "name": "devops-intelligence-platform",
        "gitSource": {
          "type": "github",
          "repo": "{{ secret('GITHUB_OWNER') }}/{{ secret('GITHUB_REPO') }}",
          "ref": "autonomous-fix-{{ now() | date('yyyyMMdd-HHmmss') }}"
        },
        "projectSettings": {
          "buildCommand": "npm run build",
          "outputDirectory": ".next"
        }
      }
    description: Deploy approved fixes to Vercel

  # =============================================================================
  # PHASE 8: NOTIFICATIONS AND MONITORING
  # =============================================================================

  - id: send_slack_notification
    type: io.kestra.plugin.core.http.Request
    uri: "{{ secret('SLACK_WEBHOOK_URL') }}"
    method: POST
    headers:
      Content-Type: "application/json"
    body: |
      {
        "text": "ðŸ¤– DevOps Intelligence Platform Update",
        "blocks": [
          {
            "type": "header",
            "text": {
              "type": "plain_text",
              "text": "ðŸ¤– Autonomous Incident Response Complete"
            }
          },
          {
            "type": "section",
            "fields": [
              {
                "type": "mrkdwn",
                "text": "*Issues Detected:* {{ outputs.process_collected_data.vars.stdout | jq('.sources | to_entries | map(.value.error_count // .value.open_issues // 0) | add') }}"
              },
              {
                "type": "mrkdwn", 
                "text": "*Auto Actions:* {{ outputs.decision_engine.vars.stdout | jq('.auto_actions') }}"
              },
              {
                "type": "mrkdwn",
                "text": "*Deployed:* {{ outputs.deployment_decision.vars.stdout | jq('.should_deploy') }}"
              },
              {
                "type": "mrkdwn",
                "text": "*Escalations:* {{ outputs.decision_engine.vars.stdout | jq('.escalations') }}"
              }
            ]
          },
          {
            "type": "section",
            "text": {
              "type": "mrkdwn",
              "text": "*AI Summary:* {{ outputs.ai_analysis_and_summary.response | jq('.summary') }}"
            }
          }
        ]
      }
    description: Send comprehensive status update to Slack

  - id: update_dashboard
    type: io.kestra.plugin.core.http.Request
    uri: "https://devops-intelligence.vercel.app/api/workflow-update"
    method: POST
    headers:
      Content-Type: "application/json"
      Authorization: "Bearer {{ secret('DASHBOARD_API_KEY') }}"
    body: |
      {
        "workflow_id": "{{ flow.id }}",
        "execution_id": "{{ taskrun.id }}",
        "timestamp": "{{ now() }}",
        "status": "completed",
        "data_collected": {{ outputs.process_collected_data.vars.stdout }},
        "ai_analysis": {{ outputs.ai_analysis_and_summary.response }},
        "decisions": {{ outputs.decision_engine.vars.stdout }},
        "deployment": {{ outputs.deployment_decision.vars.stdout }},
        "metrics": {
          "execution_time": "{{ taskrun.startDate | dateAdd(taskrun.duration, 'MILLISECONDS') | date('yyyy-MM-dd HH:mm:ss') }}",
          "issues_resolved": {{ outputs.decision_engine.vars.stdout | jq('.auto_actions') }},
          "confidence_avg": {{ outputs.decision_engine.vars.stdout | jq('.decisions | map(.confidence) | add / length') }}
        }
      }
    description: Update real-time dashboard with workflow results

# =============================================================================
# ERROR HANDLING AND RECOVERY
# =============================================================================

errors:
  - id: data_collection_failure
    type: io.kestra.core.models.flows.Flow
    tasks:
      - id: fallback_monitoring
        type: io.kestra.plugin.scripts.python.Script
        script: |
          print("Data collection failed, using cached data or manual fallback")
          # Implement fallback logic
        description: Fallback when data collection fails

  - id: ai_analysis_failure
    type: io.kestra.core.models.flows.Flow
    tasks:
      - id: manual_escalation
        type: io.kestra.plugin.core.http.Request
        uri: "{{ secret('SLACK_WEBHOOK_URL') }}"
        method: POST
        body: |
          {
            "text": "ðŸš¨ AI Analysis Failed - Manual Review Required",
            "channel": "#devops-alerts"
          }
        description: Escalate to humans when AI analysis fails

# =============================================================================
# WORKFLOW METADATA
# =============================================================================

labels:
  environment: production
  team: devops
  hackathon: ai-agents-assemble
  sponsor_tools: kestra,cline,vercel,coderabbit

description: |
  This workflow represents the core of the DevOps Intelligence Platform,
  demonstrating autonomous AI agents working together to:
  
  1. Monitor production systems continuously
  2. Analyze issues using AI-powered summarization
  3. Generate fix code autonomously using Cline CLI
  4. Review code automatically with CodeRabbit
  5. Make deployment decisions based on confidence scores
  6. Deploy fixes to production via Vercel
  7. Notify teams and update dashboards in real-time
  
  Built for the AI Agents Assemble Hackathon to showcase the integration
  of Kestra, Cline CLI, Vercel, and CodeRabbit in a production-ready
  autonomous DevOps workflow.
